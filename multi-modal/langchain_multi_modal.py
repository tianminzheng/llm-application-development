
import base64
import json
import os
import re
import requests
import time
from io import BytesIO
from typing import Union, List, Literal, Optional, Dict, Any

import matplotlib.pyplot as plt
import streamlit as st
from PIL import Image, UnidentifiedImageError
from audio_recorder_streamlit import audio_recorder
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import HumanMessage, AIMessage
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_google_community import GoogleSearchAPIWrapper
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from matplotlib.figure import Figure
from openai import OpenAI
from openai._legacy_response import HttpxBinaryResponseContent


def initialize_session_state_variables() -> None:
    """
    åˆå§‹åŒ–session stateå˜é‡
    """

    if "ready" not in st.session_state:
        st.session_state.ready = False

    if "openai" not in st.session_state:
        st.session_state.openai = None

    if "history" not in st.session_state:
        st.session_state.history = []

    if "model_type" not in st.session_state:
        st.session_state.model_type = "GPT Models from OpenAI"

    if "ai_role" not in st.session_state:
        st.session_state.ai_role = 2 * ["ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"]

    if "prompt_exists" not in st.session_state:
        st.session_state.prompt_exists = False

    if "temperature" not in st.session_state:
        st.session_state.temperature = [0.7, 0.7]

    if "audio_bytes" not in st.session_state:
        st.session_state.audio_bytes = None

    if "mic_used" not in st.session_state:
        st.session_state.mic_used = False

    if "audio_response" not in st.session_state:
        st.session_state.audio_response = None

    if "image_url" not in st.session_state:
        st.session_state.image_url = None

    if "image_description" not in st.session_state:
        st.session_state.image_description = None

    if "uploader_key" not in st.session_state:
        st.session_state.uploader_key = 0

    if "google_cse_id_validity" not in st.session_state:
        st.session_state.google_cse_id_validity = False

    if "show_uploader" not in st.session_state:
        st.session_state.show_uploader = False


class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: Any, **kwargs) -> None:
        new_text = self._extract_text(token)
        if new_text:
            self.text += new_text
            self.container.markdown(self.text)

    def _extract_text(self, token: Any) -> str:
        if isinstance(token, str):
            return token
        elif isinstance(token, list):
            return ''.join(self._extract_text(t) for t in token)
        elif isinstance(token, dict):
            return token.get('text', '')
        else:
            return str(token)


def is_openai_api_key_valid(openai_api_key: str) -> bool:
    """
    å¦‚æœç»™å®šçš„OpenAI APIå¯†é’¥æœ‰æ•ˆï¼Œåˆ™è¿”å›True
    """

    headers = {
        "Authorization": f"Bearer {openai_api_key}",
    }
    try:
        response = requests.get(
            "https://api.openai.com/v1/models", headers=headers
        )
        return response.status_code == 200
    except requests.RequestException:
        return False


def is_anthropic_api_key_valid(anthropic_api_key: str) -> bool:
    """
    å¦‚æœç»™å®šçš„Anthropic APIå¯†é’¥æœ‰æ•ˆï¼Œåˆ™è¿”å›Trueã€‚
    """

    headers = {
        "x-api-key": anthropic_api_key,
        "Content-Type": "application/json",
        "anthropic-version": "2023-06-01"
    }
    payload = {
        "model": "claude-2.1",
        "max_tokens": 10,
        "messages": [
            {"role": "user", "content": "Hello, world!"}
        ]
    }
    try:
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers=headers,
            json=payload,
        )
        return response.status_code == 200
    except requests.RequestException:
        return False


def is_google_api_key_valid(google_api_key: str) -> bool:
    """
    å¦‚æœç»™å®šçš„Google APIå¯†é’¥æœ‰æ•ˆï¼Œåˆ™è¿”å›True
    """

    if not google_api_key:
        return False

    gemini_llm = ChatGoogleGenerativeAI(
        model="gemini-pro", google_api_key=google_api_key
    )
    try:
        gemini_llm.invoke("Hello")
    except:
        return False
    else:
        return True


def are_google_api_key_cse_id_valid(
    google_api_key: str, google_cse_id: str
) -> bool:

    """
    å¦‚æœæä¾›çš„Google APIå¯†é’¥å’ŒCSE IDæœ‰æ•ˆï¼Œåˆ™è¿”å›Trueã€‚
    """

    if google_api_key and google_cse_id:
        try:
            search = GoogleSearchAPIWrapper(
                google_api_key=google_api_key,
                google_cse_id=google_cse_id,
                k=1
            )
            search.run("æˆ‘åœ¨å“ªé‡Œå¯ä»¥è·å¾—ä¸€ä¸ªGoogle CSE IDï¼Ÿ")
        except:
            return False
        else:
            return True
    else:
        return False


def check_api_keys() -> None:
    # å–æ¶ˆè®¾ç½®è¿™ä¸ªæ ‡å¿—ä»¥æ£€æŸ¥APIå¯†é’¥çš„æœ‰æ•ˆæ€§
    st.session_state.ready = False


def message_history_to_string(extra_space: bool=True) -> str:
    """
    è¿”å›åŒ…å«åœ¨st.session_state.historyä¸­çš„èŠå¤©è®°å½•çš„å­—ç¬¦ä¸²
    """

    history_list = []
    for msg in st.session_state.history:
        if isinstance(msg, HumanMessage):
            history_list.append(f"Human: {msg.content}")
        else:
            history_list.append(f"AI: {msg.content}")
    new_lines = "\n\n" if extra_space else "\n"

    return new_lines.join(history_list)


def get_chat_model(
    model: str,
    temperature: float,
    callbacks: List[BaseCallbackHandler]
) -> Union[ChatOpenAI, ChatAnthropic, ChatGoogleGenerativeAI, None]:

    """
    æ ¹æ®ç»™å®šçš„æ¨¡å‹åç§°è·å–ç›¸åº”çš„èŠå¤©æ¨¡å‹ã€‚
    """

    model_map = {
        "gpt-": ChatOpenAI,
        "claude-": ChatAnthropic,
        "gemini-": ChatGoogleGenerativeAI
    }
    for prefix, ModelClass in model_map.items():
        if model.startswith(prefix):
            return ModelClass(
                model=model,
                temperature=temperature,
                streaming=True,
                callbacks=callbacks
            )
    return None


def process_with_images(
    llm: Union[ChatOpenAI, ChatAnthropic, ChatGoogleGenerativeAI],
    message_content: str,
    image_urls: List[str]
) -> str:

    """
    ä½¿ç”¨è¯­è¨€æ¨¡å‹å¤„ç†ç»™å®šçš„å†å²æŸ¥è¯¢åŠå…¶ç›¸å…³è”çš„å›¾åƒã€‚
    """

    print(message_content)

    content_with_images = (
        [{"type": "text", "text": message_content}] +
        [{"type": "image_url", "image_url": {"url": url}} for url in image_urls]
    )
    message_with_images = [HumanMessage(content=content_with_images)]

    return llm.invoke(message_with_images).content


def perform_query(
    query: str,
    model: str,
    image_urls: List[str],
    temperature: float=0.7,
) -> Union[str, None]:

    """
    æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆæ–‡æœ¬ã€‚
    èŠå¤©æç¤ºå’Œæ¶ˆæ¯å†å²å­˜å‚¨åœ¨st.session_stateå˜é‡ä¸­ã€‚
    """

    try:
        llm = get_chat_model(model, temperature, [StreamHandler(st.empty())])
        if llm is None:
            st.error(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model}", icon="ğŸš¨")
            return None

        # è·å–èŠå¤©å†å²
        chat_history = st.session_state.history
        print(chat_history)

        history_query = {"chat_history": chat_history, "input": query}
        print(history_query)

        # è·å–ç³»ç»Ÿæ¶ˆæ¯
        message_with_no_image = st.session_state.chat_prompt.invoke(history_query)
        print(message_with_no_image)
        message_content = message_with_no_image.messages[0].content
        print(message_content)

        # æ‰§è¡Œå›¾ç‰‡å¯¹è¯
        if image_urls:
            generated_text = process_with_images(llm, message_content, image_urls)
            human_message = HumanMessage(
                content=query, additional_kwargs={"image_urls": image_urls}
            )
        # æ‰§è¡Œæ–‡æœ¬å¯¹è¯
        else:
            generated_text = llm.invoke(message_with_no_image).content
            human_message = HumanMessage(content=query)

        if isinstance(generated_text, list):
            generated_text = generated_text[0]["text"]

        # æ·»åŠ èŠå¤©å†å²
        st.session_state.history.append(human_message)
        st.session_state.history.append(AIMessage(content=generated_text))
        print(st.session_state.history)

        return generated_text
    except Exception as e:
        st.error(f"å‡ºç°å¼‚å¸¸: {e}", icon="ğŸš¨")
        return None


def openai_create_image(
    description: str, model: str="dall-e-3", size: str="1024x1024"
) -> Optional[str]:

    """åŸºäºæè¿°ç”Ÿæˆå›¾åƒ"""

    try:
        with st.spinner("AI is generating..."):
            response = st.session_state.openai.images.generate(
                model=model,
                prompt=description,
                size=size,
                quality="standard",
                n=1,
            )
        image_url = response.data[0].url
    except Exception as e:
        image_url = None
        st.error(f"An error occurred: {e}", icon="ğŸš¨")

    return image_url

def display_text_with_equations(text: str):
    # Replace inline LaTeX equation delimiters \\( ... \\) with $
    modified_text = text.replace("\\(", "$").replace("\\)", "$")

    # Replace block LaTeX equation delimiters \\[ ... \\] with $$
    modified_text = modified_text.replace("\\[", "$$").replace("\\]", "$$")

    # Use st.markdown to display the formatted text with equations
    st.markdown(modified_text)


def read_audio(audio_bytes: bytes) -> Optional[str]:
    """
    è¯»å–éŸ³é¢‘æµå¹¶è¿”å›å¯¹åº”çš„æ–‡æœ¬
    """
    try:
        audio_data = BytesIO(audio_bytes)
        audio_data.name = "recorded_audio.wav"  # dummy name

        transcript = st.session_state.openai.audio.transcriptions.create(
            model="whisper-1", file=audio_data
        )
        text = transcript.text
    except Exception as e:
        text = None
        st.error(f"å‡ºç°å¼‚å¸¸: {e}", icon="ğŸš¨")

    return text


def input_from_mic() -> Optional[str]:
    """
    å°†éº¦å…‹é£çš„éŸ³é¢‘è¾“å…¥è½¬æ¢ä¸ºæ–‡æœ¬å¹¶è¿”å›ã€‚
    å¦‚æœæ²¡æœ‰éŸ³é¢‘è¾“å…¥ï¼Œåˆ™è¿”å›Noneã€‚
    """

    time.sleep(0.5)
    audio_bytes = audio_recorder(
        pause_threshold=3.0, text="Speak", icon_size="2x",
        recording_color="#e87070", neutral_color="#6aa36f"
    )

    if audio_bytes == st.session_state.audio_bytes or audio_bytes is None:
        return None
    else:
        st.session_state.audio_bytes = audio_bytes
        return read_audio(audio_bytes)


def perform_tts(text: str) -> Optional[HttpxBinaryResponseContent]:
    """
    å°†æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œæ‰§è¡Œæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªéŸ³é¢‘å“åº”ã€‚
    """

    try:
        with st.spinner("TTSå¤„ç†ä¸­..."):
            audio_response = st.session_state.openai.audio.speech.create(
                model="tts-1",
                voice="fable",
                input=text,
            )
    except Exception as e:
        audio_response = None
        st.error(f"å‘ç”Ÿå¼‚å¸¸: {e}", icon="ğŸš¨")

    return audio_response


def play_audio(audio_response: HttpxBinaryResponseContent) -> None:
    """
    å°†æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç”Ÿæˆçš„éŸ³é¢‘å“åº”ä½œä¸ºè¾“å…¥ï¼Œå¹¶æ’­æ”¾è¯¥éŸ³é¢‘ã€‚
    """

    audio_data = audio_response.read()

    # å°†éŸ³é¢‘æ•°æ®ç¼–ç ä¸ºBase64æ ¼å¼
    b64 = base64.b64encode(audio_data).decode("utf-8")

    # åˆ›å»ºä¸€ä¸ªMarkdownå­—ç¬¦ä¸²ï¼Œç”¨äºåµŒå…¥å¸¦æœ‰Base64æºçš„éŸ³é¢‘æ’­æ”¾å™¨ã€‚
    md = f"""
        <audio controls autoplay style="width: 100%;">
        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        ä½ çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³å…ƒç´ .
        </audio>
        """

    # ä½¿ç”¨Streamlitæ¥æ¸²æŸ“éŸ³é¢‘æ’­æ”¾å™¨
    st.markdown(md, unsafe_allow_html=True)


def image_to_base64(image: Image) -> str:
    """
    å°†PILå›¾åƒå¯¹è±¡è½¬æ¢ä¸ºBase64ç¼–ç çš„å›¾åƒï¼Œå¹¶è¿”å›å¾—åˆ°çš„ç¼–ç å›¾åƒå­—ç¬¦ä¸²ï¼Œä»¥ä¾¿ç”¨ä½œURLçš„æ›¿ä»£å“ã€‚
    """

    # å°†å½“å‰å›¾åƒè½¬æ¢ä¸ºRGBæ¨¡å¼ï¼Œå¹¶ä¸”è¿”å›æ–°çš„å›¾åƒ
    if image.mode != "RGB":
        image = image.convert("RGB")

    # å°†å›¾åƒä¿å­˜ä¸ºBytesIOå¯¹è±¡
    buffered_image = BytesIO()
    image.save(buffered_image, format="JPEG")

    # å°†BytesIOå¯¹è±¡è½¬æ¢ä¸ºå­—èŠ‚å¹¶é‡‡ç”¨base64è¿›è¡Œç¼–ç 
    img_str = base64.b64encode(buffered_image.getvalue())

    # å°†å­—èŠ‚è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    base64_image = img_str.decode("utf-8")

    return f"data:image/jpeg;base64,{base64_image}"


def shorten_image(image: Image, max_pixels: int=1024) -> Image:
    """
    æ¥æ”¶ä¸€ä¸ªå›¾åƒå¯¹è±¡ä½œä¸ºè¾“å…¥ï¼Œå¦‚æœå›¾åƒå¤§å°è¶…è¿‡æœ€å¤§åƒç´  x æœ€å¤§åƒç´ çš„é™åˆ¶ï¼Œåˆ™ç¼©çŸ­å›¾åƒå°ºå¯¸ã€‚
    """

    if max(image.width, image.height) > max_pixels:
        if image.width > image.height:
            new_width, new_height = 1024, image.height * 1024 // image.width
        else:
            new_width, new_height = image.width * 1024 // image.height, 1024

        image = image.resize((new_width, new_height))

    return image


def upload_image_files_return_urls(
    type: List[str]=["jpg", "jpeg", "png", "bmp"]
) -> List[str]:

    """
    ä¸Šä¼ å›¾åƒæ–‡ä»¶ï¼Œå°†å®ƒä»¬è½¬æ¢ä¸ºBase64ç¼–ç çš„å›¾åƒï¼Œå¹¶è¿”å›ç»“æœç¼–ç å›¾åƒçš„åˆ—è¡¨ã€‚
    """

    st.write("")
    st.write("**å›¾åƒå¯¹è¯**")
    source = st.radio(
        label="å›¾åƒé€‰æ‹©",
        options=("Uploaded", "From URL"),
        horizontal=True,
        label_visibility="collapsed",
    )
    image_urls = []

    if source == "Uploaded":
        uploaded_files = st.file_uploader(
            label="ä¸Šä¼ å›¾åƒ",
            type=type,
            accept_multiple_files=True,
            label_visibility="collapsed",
            key="image_upload_" + str(st.session_state.uploader_key),
        )
        if uploaded_files:
            try:
                for image_file in uploaded_files:
                    image = Image.open(image_file)
                    thumbnail = shorten_image(image, 300)
                    st.image(thumbnail)
                    image = shorten_image(image, 1024)
                    image_urls.append(image_to_base64(image))
            except UnidentifiedImageError as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}", icon="ğŸš¨")
    else:
        image_url = st.text_input(
            label="å›¾åƒURL",
            label_visibility="collapsed",
            key="image_url_" + str(st.session_state.uploader_key),
        )
        if image_url:
            if is_url(image_url):
                st.image(image_url)
                image_urls = [image_url]
            else:
                st.error("è¾“å…¥ä¸€ä¸ªæ­£ç¡®çš„URL", icon="ğŸš¨")

    return image_urls


def fig_to_base64(fig: Figure) -> str:
    """
    å°†ä¸€ä¸ªå›¾å½¢å¯¹è±¡è½¬æ¢ä¸ºBase64ç¼–ç çš„å›¾åƒï¼Œå¹¶è¿”å›å¾—åˆ°çš„ç¼–ç å›¾åƒï¼Œä»¥ä¾¿ä»£æ›¿URLä½¿ç”¨ã€‚
    """

    buffer = BytesIO()
    fig.savefig(buffer, format="png")
    buffer.seek(0)
    image = Image.open(buffer)

    return image_to_base64(image)


def is_url(text: str) -> bool:
    """
    ç¡®å®æ–‡æœ¬æ˜¯å¦ä¸ºä¸€ä¸ªåˆæ³•çš„URL
    """

    regex = r"(http|https)://([\w_-]+(?:\.[\w_-]+)+)(:\S*)?"
    p = re.compile(regex)
    match = p.match(text)
    if match:
        return True
    else:
        return False


def reset_conversation() -> None:
    """
    é‡ç½®session_stateå˜é‡ä»¥é‡ç½®å¯¹è¯
    """

    st.session_state.history = []
    st.session_state.ai_role[1] = st.session_state.ai_role[0]
    st.session_state.prompt_exists = False
    st.session_state.temperature[1] = st.session_state.temperature[0]
    st.session_state.audio_response = None
    st.session_state.uploader_key = 0


def switch_between_apps() -> None:
    """
    Keep the chat settings when switching the mode.
    """

    st.session_state.temperature[1] = st.session_state.temperature[0]
    st.session_state.ai_role[1] = st.session_state.ai_role[0]


def set_prompts() -> None:
    """
    è®¾ç½®æç¤ºè¯
    """

    st.session_state.chat_prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            f"{st.session_state.ai_role[0]} "
            f"ä½ çš„ç›®æ ‡æ˜¯å›ç­”äººç±»çš„è¯¢é—®ã€‚å¦‚æœä¿¡æ¯ä¸å¯ç”¨ï¼Œæ˜ç¡®å‘ŠçŸ¥äººç±»æ— æ³•æ‰¾åˆ°ç­”æ¡ˆã€‚"
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
    ])


def print_conversation(no_of_msgs: Union[Literal["All"], int]) -> None:
    """
    æ‰“å°å­˜å‚¨åœ¨st.session_state.historyä¸­çš„å¯¹è¯
    """

    if no_of_msgs == "All":
        no_of_msgs = len(st.session_state.history)

    for msg in st.session_state.history[-no_of_msgs:]:
        if isinstance(msg, HumanMessage):
            with st.chat_message("human"):
                st.write(msg.content)
        else:
            with st.chat_message("ai"):
                display_text_with_equations(msg.content)

        if urls := msg.additional_kwargs.get("image_urls"):
            for url in urls:
                st.image(url)

    # æ‰§è¡ŒTTS
    if (
        st.session_state.model_type == "GPT Models from OpenAI"
        and st.session_state.audio_response is not None
    ):
        play_audio(st.session_state.audio_response)
        st.session_state.audio_response = None


def deserialize_messages(
    serialized_messages: List[Dict]
) -> List[Union[HumanMessage, AIMessage]]:

    """
    ä»å­—å…¸åˆ—è¡¨ååºåˆ—åŒ–æ¶ˆæ¯åˆ—è¡¨
    """

    deserialized_messages = []
    for msg in serialized_messages:
        if msg['type'] == 'human':
            deserialized_messages.append(HumanMessage(**msg))
        elif msg['type'] == 'ai':
            deserialized_messages.append(AIMessage(**msg))
    return deserialized_messages


def show_uploader() -> None:
    """
    è®¾ç½®æ˜¾ç¤ºä¸Šä¼ å™¨çš„æ ‡å¿—
    """

    st.session_state.show_uploader = True


def check_conversation_keys(lst: List[Dict[str, Any]]) -> bool:
    """
    æ£€æŸ¥ç»™å®šåˆ—è¡¨ä¸­çš„æ‰€æœ‰é¡¹ç›®æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å¯¹è¯æ¡ç›®ã€‚
    """

    return all(
        isinstance(item, dict) and
        isinstance(item.get("content"), str) and
        isinstance(item.get("type"), str) and
        isinstance(item.get("additional_kwargs"), dict)
        for item in lst
    )


def load_conversation() -> bool:
    """
    ä»JSONæ–‡ä»¶åŠ è½½å¯¹è¯
    """

    st.write("")
    st.write("**Choose a (JSON) conversation file**")
    uploaded_file = st.file_uploader(
        label="Load conversation", type="json", label_visibility="collapsed"
    )
    if uploaded_file:
        try:
            data = json.load(uploaded_file)
            if isinstance(data, list) and check_conversation_keys(data):
                st.session_state.history = deserialize_messages(data)
                return True
            st.error(
                f"The uploaded data does not conform to the expected format.", icon="ğŸš¨"
            )
        except Exception as e:
            st.error(f"An error occurred: {e}", icon="ğŸš¨")

    return False


def create_text(model: str) -> None:
    """
    ä»¥LLMä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”¨æˆ·è¾“å…¥ç”Ÿæˆæ–‡æœ¬
    """

    general_role = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"
    roles = (
        general_role
    )

    with st.sidebar:

        if st.session_state.model_type == "GPT Models from OpenAI":
            st.write("")
            st.write("**TTS**")
            st.session_state.tts = st.radio(
                label="TTS",
                options=("Enabled", "Disabled", "Auto"),
                # horizontal=True,
                index=1,
                label_visibility="collapsed",
            )
        st.write("")
        st.write("**Temperature**")
        st.session_state.temperature[0] = st.slider(
            label="Temperature",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.temperature[1],
            step=0.1,
            format="%.1f",
            label_visibility="collapsed",
        )
        st.write("")
        st.write("**æ˜¾ç¤ºæ¶ˆæ¯**")
        no_of_msgs = st.radio(
            label="æ˜¾ç¤ºæ¶ˆæ¯",
            options=("All", 20, 10),
            label_visibility="collapsed",
            horizontal=True,
            index=2,
        )

    st.write("")
    st.write("##### å‘é€AIæ¶ˆæ¯")
    st.session_state.ai_role[0] = st.selectbox(
        label="AIçš„è§’è‰²",
        options=roles,
        index=roles.index(st.session_state.ai_role[1]),
        label_visibility="collapsed",
    )

    if st.session_state.ai_role[0] != st.session_state.ai_role[1]:
        reset_conversation()
        st.rerun()

    st.write("")
    st.write("##### å’ŒAIå¯¹è¯")

    # Print conversation
    print_conversation(no_of_msgs)

    if st.session_state.show_uploader and load_conversation():
        st.session_state.show_uploader = False
        st.rerun()

    set_prompts()

    with st.sidebar:
        image_urls = upload_image_files_return_urls()

    if st.session_state.model_type == "GPT Models from OpenAI":
        audio_input = input_from_mic()
        if audio_input is not None:
            query = audio_input
            st.session_state.prompt_exists = True
            st.session_state.mic_used = True

    text_input = st.chat_input(placeholder="è¾“å…¥æŸ¥è¯¢æ¡ä»¶")

    if text_input:
        query = text_input.strip()
        st.session_state.prompt_exists = True

    if st.session_state.prompt_exists:
        with st.chat_message("human"):
            st.write(query)

        with st.chat_message("ai"):
            generated_text = perform_query(
                query=query,
                model=model,
                image_urls=image_urls,
                temperature=st.session_state.temperature[0],
            )
            fig = plt.gcf()
            if fig and fig.get_axes():
                generated_image_url = fig_to_base64(fig)
                st.session_state.history[-1].additional_kwargs["image_urls"] = [
                    generated_image_url
                ]
        if (
            st.session_state.model_type == "GPT Models from OpenAI"
            and generated_text is not None
        ):
            # TTS under two conditions
            cond1 = st.session_state.tts == "Enabled"
            cond2 = st.session_state.tts == "Auto" and st.session_state.mic_used
            if cond1 or cond2:
                st.session_state.audio_response = perform_tts(generated_text)
            st.session_state.mic_used = False

        st.session_state.prompt_exists = False

        if generated_text is not None:
            st.session_state.uploader_key += 1
            st.rerun()


def create_image(model: str) -> None:
    """
    æ ¹æ®ç”¨æˆ·æè¿°ç”Ÿæˆå›¾åƒ
    """

    with st.sidebar:
        st.write("")
        st.write("**åƒç´ **")
        image_size = st.radio(
            label="$\\hspace{0.1em}\\texttt{Pixel size}$",
            options=("1024x1024", "1792x1024", "1024x1792"),
            # horizontal=True,
            index=0,
            label_visibility="collapsed",
        )

    st.write("")
    st.write("##### æè¿°å›¾åƒ")

    if st.session_state.image_url is not None:
        st.info(st.session_state.image_description)
        st.image(image=st.session_state.image_url, use_column_width=True)

    # Get an image description using the microphone
    if st.session_state.model_type == "GPT Models from OpenAI":
        audio_input = input_from_mic()
        if audio_input is not None:
            st.session_state.image_description = audio_input
            st.session_state.prompt_exists = True

    # Get an image description using the keyboard
    text_input = st.chat_input(
        placeholder="è¾“å…¥å›¾åƒçš„æè¿°",
    )
    if text_input:
        st.session_state.image_description = text_input.strip()
        st.session_state.prompt_exists = True

    if st.session_state.prompt_exists:
        st.session_state.image_url = openai_create_image(
            st.session_state.image_description, model, image_size
        )
        st.session_state.prompt_exists = False
        if st.session_state.image_url is not None:
            st.rerun()


def create_text_image() -> None:
    """
    ä½¿ç”¨LLMç”Ÿæˆæ–‡æœ¬æˆ–å›¾åƒ
    """

    page_title = "LangChainå¤šæ¨¡æ€åº”ç”¨"
    page_icon = "ğŸ“š"

    st.set_page_config(
        page_title=page_title,
        page_icon=page_icon,
        layout="centered"
    )

    st.write(f"## {page_icon} $\,${page_title}")

    initialize_session_state_variables()

    with st.sidebar:

        st.write("")
        st.write("**Model Type**")
        st.session_state.model_type = st.sidebar.radio(
            label="Model type",
            options=(
                "GPT Models from OpenAI",
                "Claude Models from Anthropic",
                "Gemini Models from Google",
            ),
            on_change=check_api_keys,
            label_visibility="collapsed",
        )
        st.write("")
        if st.session_state.model_type in (
                "GPT Models from OpenAI", "Claude Models from Anthropic"
        ):
            validity = "(Verified)" if st.session_state.ready else ""
            if st.session_state.model_type == "GPT Models from OpenAI":
                st.write(
                    "**OpenAI API Key** ",
                    f"<small>:blue[{validity}]</small>",
                    unsafe_allow_html=True
                )
                openai_api_key = st.text_input(
                    label="OpenAI API Key",
                    type="password",
                    on_change=check_api_keys,
                    label_visibility="collapsed",
                )
            else:
                st.write(
                    "**Anthropic API Key** ",
                    f"<small>:blue[{validity}]</small>",
                    unsafe_allow_html=True
                )
                anthropic_api_key = st.text_input(
                    label="Anthropic API Key",
                    type="password",
                    on_change=check_api_keys,
                    label_visibility="collapsed",
                )
        else:
            validity = "(Verified)" if st.session_state.ready else ""
            st.write(
                "**Google API Key** ",
                f"<small>:blue[{validity}]</small>",
                unsafe_allow_html=True
            )
            google_api_key = st.text_input(
                label="Google API Key",
                type="password",
                on_change=check_api_keys,
                label_visibility="collapsed",
            )
            if st.session_state.google_cse_id_validity:
                validity = "(Verified)"
            else:
                validity = ""
            st.write(
                "**Google CSE ID** ",
                f"<small>:blue[{validity}]</small>",
                unsafe_allow_html=True
            )
            google_cse_id = st.text_input(
                label="Google CSE ID",
                type="password",
                value="",
                on_change=check_api_keys,
                label_visibility="collapsed",
            )
        authentication = True

        os.environ["BING_SEARCH_URL"] = "https://api.bing.microsoft.com/v7.0/search"

    if authentication:
        if not st.session_state.ready:

            if st.session_state.model_type in (
                    "GPT Models from OpenAI", "Claude Models from Anthropic"
            ):
                if st.session_state.model_type == "GPT Models from OpenAI":
                    if is_openai_api_key_valid(openai_api_key):
                        os.environ["OPENAI_API_KEY"] = openai_api_key
                        st.session_state.openai = OpenAI()
                        st.session_state.ready = True
                else:
                    if is_anthropic_api_key_valid(anthropic_api_key):
                        os.environ["ANTHROPIC_API_KEY"] = anthropic_api_key
                        st.session_state.ready = True
            else:
                if is_google_api_key_valid(google_api_key):
                    os.environ["GOOGLE_API_KEY"] = google_api_key
                    st.session_state.ready = True
                    if are_google_api_key_cse_id_valid(
                            google_api_key, google_cse_id
                    ):
                        os.environ["GOOGLE_CSE_ID"] = google_cse_id
                        st.session_state.google_cse_id_validity = True
                    else:
                        st.session_state.google_cse_id_validity = False

            if st.session_state.ready:
                st.rerun()
            else:
                st.image("D:\\demo.png")
                st.stop()
    else:
        st.info("**åœ¨ä¾§è¾¹æ è¾“å…¥æ­£ç¡®çš„å¯†ç **")
        st.stop()

    gpt_models = ("gpt-4o-mini", "gpt-4o")
    claude_models = ("claude-3-haiku-20240307", "claude-3-5-sonnet-20240620")
    gemini_models = ("gemini-1.5-flash", "gemini-1.5-pro")

    with st.sidebar:
        st.write("")
        st.write("**Model**")

        if st.session_state.model_type == "GPT Models from OpenAI":
            model_options = gpt_models + ("dall-e-3",)
        elif st.session_state.model_type == "Claude Models from Anthropic":
            model_options = claude_models
        else:
            model_options = gemini_models

        model = st.radio(
            label="Models",
            options=model_options,
            label_visibility="collapsed",
            index=1,
            on_change=switch_between_apps,
        )

    if model == "dall-e-3":
        create_image(model)
    else:
        create_text(model)

if __name__ == "__main__":
    create_text_image()
